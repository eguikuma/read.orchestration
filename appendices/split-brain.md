<div align="right">
<img src="https://img.shields.io/badge/AI-ASSISTED_STUDY-3b82f6?style=for-the-badge&labelColor=1e293b&logo=bookstack&logoColor=white" alt="AI Assisted Study" />
</div>

# appendix：スプリットブレイン問題

## はじめに

[02-architecture](../02-architecture.md) では、etcd がクラスタのすべての状態を保存する<strong>分散キーバリューストア</strong>であり、<strong>唯一の情報源（Single Source of Truth）</strong>として機能することを学びました

また、[05-self-healing](../05-self-healing.md) では、ノードからのハートビートが途絶えた場合に Node コントローラがノードを NotReady にマークし、Pod を退避させる仕組みを学びました

しかし、ノード障害とネットワーク障害は同じではありません

ノードが「停止した」のではなく、「通信できなくなっただけ」の場合、何が起きるのでしょうか

分断されたノード上では Pod がまだ動き続けているかもしれません

この付録では、ネットワークが分断されたときにクラスタで何が起きるかを見ていきます

分散システムの古典的な問題である<strong>スプリットブレイン</strong>と、Kubernetes がどのようにこの問題に対処しているかを学びます

---

## このページで学ぶこと

- <strong>スプリットブレインの概念</strong>
  - ネットワーク分断によりクラスタが複数のグループに分かれ、それぞれが独立に動作する問題
- <strong>ネットワーク分断のシナリオ</strong>
  - コントロールプレーンとワーカーノード間、および etcd クラスタ内部の分断
- <strong>etcd とクォーラムによる保護</strong>
  - Raft の過半数原則がスプリットブレインを防ぐ仕組み
- <strong>ノード障害検知の限界</strong>
  - ハートビートの途絶だけでは「停止」と「到達不能」を区別できない問題
- <strong>二重実行の危険</strong>
  - 分断されたノードの Pod と代替 Pod が同時に動く状態の影響
- <strong>Lease とフェンシングによる緩和</strong>
  - スプリットブレインの影響を軽減する手法

---

## 目次

1. [スプリットブレインとは](#スプリットブレインとは)
2. [ネットワーク分断のシナリオ](#ネットワーク分断のシナリオ)
3. [etcd とクォーラム](#etcd-とクォーラム)
4. [ノード障害検知の限界](#ノード障害検知の限界)
5. [二重実行の可能性](#二重実行の可能性)
6. [Lease とフェンシング](#lease-とフェンシング)
7. [用語集](#用語集)
8. [参考資料](#参考資料)

---

## スプリットブレインとは

<strong>スプリットブレイン（Split-Brain）</strong>は、分散システムにおける古典的な問題です

ネットワーク分断（Network Partition）によって、クラスタが 2 つ以上のグループに分かれ、各グループが「自分が正しい」と思い込んで独立に動作してしまう状態を指します

名前の由来は、1 つの脳（Brain）が 2 つに分断（Split）されたかのように振る舞うことから来ています

### なぜ危険なのか

通常、クラスタ内のすべてのノードは 1 つのコントロールプレーンの管理下にあり、etcd が唯一の情報源として一貫性を保っています

しかし、ネットワークが分断されると、この前提が崩れます

分断された各グループが独立して判断を下し始めると、以下のような問題が発生する可能性があります

| 問題           | 説明                                                                 |
| -------------- | -------------------------------------------------------------------- |
| データの不一致 | 分断された各グループが異なるデータを書き込み、整合性が失われる       |
| 二重実行       | 同じアプリケーションが複数のグループで同時に動作し、データが破損する |
| リソースの競合 | 共有リソース（ストレージなど）に対して複数のノードが同時に書き込む   |

スプリットブレインは、分散システムを設計するうえで避けて通れない課題です

Kubernetes は、etcd の Raft 合意アルゴリズムと Lease の仕組みを使って、この問題の影響を最小限に抑えています

---

## ネットワーク分断のシナリオ

ネットワーク分断は、さまざまな原因で発生します

物理的なネットワークケーブルの断線、ネットワークスイッチの故障、データセンター間の接続断などが考えられます

ここでは、Kubernetes クラスタで発生しうる代表的な分断シナリオを見ていきます

### シナリオ 1：コントロールプレーンとワーカーノード間の分断

コントロールプレーンと一部のワーカーノードの間でネットワークが断絶するケースです

```
┌───────────────────────┐          ┌──────────────────┐
│  コントロールプレーン   │          │  ワーカーノード群  │
│                       │   ×××    │                  │
│  API Server           │←─×××─→  │  kubelet         │
│  etcd                 │   ×××    │  Pod A, Pod B    │
│  Controller Manager   │          │                  │
│  Scheduler            │          │                  │
└───────────────────────┘          └──────────────────┘
     ネットワーク分断
```

この場合、コントロールプレーンから見ると、分断されたノードはハートビートが途絶えた「応答なし」の状態になります

しかし、分断されたノード自体は正常に動作しており、Pod もそのまま動き続けています

### シナリオ 2：etcd クラスタ内部の分断

etcd が複数のインスタンスで動作している場合、etcd インスタンス間のネットワークが分断されるケースです

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  etcd ノード 1│     │  etcd ノード 2│     │  etcd ノード 3│
│  (リーダー)  │     │  (フォロワー) │     │  (フォロワー) │
└──────┬──────┘     └──────┬──────┘     └──────┬──────┘
       │                   │                   │
       │    ×××            │                   │
       ├───×××─────────────┤                   │
       │    ×××            │                   │
       │                   ├───────────────────┤
       │                   │      正常な通信     │
```

この例では、etcd ノード 1 がノード 2、ノード 3 から分断されています

この場合に何が起きるかは、次のセクションで説明するクォーラムの仕組みが鍵になります

### 「死亡」ではなく「到達不能」

ネットワーク分断の本質的な難しさは、分断されたノードが<strong>停止しているのではなく、到達できないだけ</strong>という点にあります

ノードが停止していれば、その上の Pod も停止しています

しかし、ネットワーク分断の場合、ノードは正常に動作しており、Pod も動き続けています

この区別ができないことが、スプリットブレイン問題の根本的な原因です

---

## etcd とクォーラム

スプリットブレインに対する Kubernetes の最も重要な防御は、etcd が内部で使用する<strong>Raft 合意アルゴリズム</strong>のクォーラム（過半数）の仕組みです

[raft-consensus](./raft-consensus.md) で学んだ Raft の過半数の原則が、ここで重要な役割を果たします

### クォーラムの仕組み

etcd は、書き込みを受け付けるために<strong>過半数（クォーラム）のインスタンスの合意</strong>を必要とします

[raft-consensus](./raft-consensus.md) で見た通り、この過半数の条件により、2 つのグループが同時に異なるデータを書き込むことが防がれます

どの 2 つの過半数にも、必ず少なくとも 1 つの共通メンバーが存在するためです

### 分断時の挙動

3 ノードの etcd クラスタで分断が発生した場合の挙動を見てみましょう

<strong>1 ノードが分断された場合</strong>

| グループ           | ノード数 | クォーラム（2） | 書き込み |
| ------------------ | -------- | --------------- | -------- |
| 多数派（2 ノード） | 2        | 達成            | 可能     |
| 少数派（1 ノード） | 1        | 未達成          | 不可     |

残りの 2 ノードがクォーラムを維持しているため、多数派グループは書き込みを続行できます

分断された 1 ノードは単独ではクォーラムを満たせないため、書き込みを受け付けません

これにより、2 つのグループが同時に異なるデータを書き込む「スプリットブレイン」を防いでいます

<strong>2 ノードが分断された場合</strong>

| グループ               | ノード数 | クォーラム（2） | 書き込み |
| ---------------------- | -------- | --------------- | -------- |
| グループ A（1 ノード） | 1        | 未達成          | 不可     |
| グループ B（2 ノード） | 2        | 達成            | 可能     |

この場合も、クォーラムを満たすグループだけが書き込みを行えるため、データの一貫性は保たれます

<strong>均等に分断された場合（偶数ノード）</strong>

もし 4 ノードの etcd クラスタが 2 対 2 に分断されたらどうなるでしょうか

| グループ               | ノード数 | クォーラム（3） | 書き込み |
| ---------------------- | -------- | --------------- | -------- |
| グループ A（2 ノード） | 2        | 未達成          | 不可     |
| グループ B（2 ノード） | 2        | 未達成          | 不可     |

どちらのグループもクォーラム（3）を満たせないため、<strong>クラスタ全体が書き込みを停止します</strong>

これは可用性の低下ですが、データの一貫性は守られます

[raft-consensus](./raft-consensus.md) で「etcd のインスタンス数に奇数が推奨される」理由を学びましたが、このシナリオはその理由をさらに補強します

偶数ノードでは均等分断時にクラスタ全体が停止するリスクがあるのに対し、奇数ノードでは必ず多数派が存在します

### クォーラムの限界

クォーラムは etcd のデータの一貫性を保護しますが、クラスタ全体のスプリットブレインを完全には解決しません

etcd への書き込みは保護されますが、分断されたノード上で動き続けている Pod の問題は残ります

この点は、次のセクション以降で詳しく見ていきます

---

## ノード障害検知の限界

[05-self-healing](../05-self-healing.md) で学んだように、Kubernetes はハートビートと Lease の仕組みでノードの正常性を監視しています

ノードからのハートビートが 50 秒途絶えると、Node コントローラはそのノードを NotReady にマークします

しかし、この仕組みには根本的な限界があります

### 「停止」と「到達不能」の区別ができない

ハートビートが途絶えた原因は、以下のどちらでもありえます

| 原因                     | ノードの状態     | Pod の状態     |
| ------------------------ | ---------------- | -------------- |
| ノードが停止した         | 停止している     | 停止している   |
| ネットワークが分断された | 正常に動いている | 動き続けている |

Node コントローラは、ハートビートの途絶だけでは、この 2 つを区別できません

どちらの場合も、ノードを NotReady にマークし、同じ対応をとります

### 分断されたノードの視点

ネットワーク分断の場合、分断されたノード側から見ると以下のような状況になっています

- kubelet は正常に動作している
- Pod も正常に動作している
- しかし、API Server に到達できないため、ハートビートを送信できない
- API Server からの新しい指示も受け取れない

分断されたノード上の kubelet は、最後に受け取った Pod の仕様に基づいて、Pod を動かし続けます

kubelet 自身は Pod を停止する理由がないため、コントロールプレーンとの通信が回復するまで Pod を維持します

---

## 二重実行の可能性

ノード障害検知の限界から、ネットワーク分断時に<strong>同じアプリケーションの同じ Pod が 2 つのノードで同時に動く「二重実行」</strong>状態が発生する可能性があります

### 二重実行が発生する流れ

[05-self-healing](../05-self-healing.md) で学んだノード障害時の Pod 退避の流れを、ネットワーク分断の観点から見直してみましょう

```
1. ネットワーク分断が発生
   ノード 2 がコントロールプレーンから到達不能になる

2. ハートビートが途絶える
   Node コントローラがノード 2 を NotReady にマーク

3. Taint の付与と猶予時間
   5 分間の猶予の後、Pod が退避対象になる

4. ReplicaSet コントローラが Pod の不足を検知
   別のノード（ノード 3）に新しい Pod を作成

5. しかし、ノード 2 では元の Pod がまだ動いている
   ノード 2 は停止していないため、Pod は動き続けている
```

この結果、同じアプリケーションの Pod がノード 2 とノード 3 の両方で同時に動作する状態になります

### ステートレスとステートフルでの影響の違い

二重実行の影響は、アプリケーションの性質によって大きく異なります

<strong>ステートレスなアプリケーション</strong>

Web サーバーのように、リクエストごとに独立して処理を行うステートレスなアプリケーションでは、二重実行の影響は限定的です

同じアプリケーションの 2 つのインスタンスが動いていても、それぞれ独立にリクエストを処理するだけであり、データの破損は発生しません

ネットワークが復旧すれば、余分な Pod は削除されます

<strong>ステートフルなアプリケーション</strong>

データベースのように状態を持つステートフルなアプリケーションでは、二重実行は<strong>データの整合性が壊れる重大な問題</strong>になりえます

たとえば、2 つのデータベースインスタンスが同じストレージに同時に書き込みを行うと、データが破損する可能性があります

| アプリケーション                 | 二重実行の影響 | 理由                                                                   |
| -------------------------------- | -------------- | ---------------------------------------------------------------------- |
| ステートレス（Web サーバーなど） | 限定的         | 各インスタンスが独立に動作し、共有状態がない                           |
| ステートフル（データベースなど） | 重大           | 共有リソースへの同時書き込みにより、データの整合性が壊れる可能性がある |

---

## Lease とフェンシング

スプリットブレイン問題を完全に解決することは困難ですが、影響を緩和するための手法がいくつか存在します

### Lease（リース）

<strong>Lease</strong>は、リソースの利用権に<strong>有効期限を設ける</strong>仕組みです

[05-self-healing](../05-self-healing.md) で学んだ Lease オブジェクトは、ノードの生存確認に使われていました

Lease の基本的な考え方は、「権限は永久ではなく、定期的に更新しなければ失効する」というものです

ネットワークが分断された場合、分断されたノードは Lease を更新できなくなります

Lease が期限切れになると、そのノードが保持していたリソースの利用権は自動的に失効します

これにより、分断されたノードが無期限にリソースを占有し続けることを防ぎます

### フェンシング（Fencing）

<strong>フェンシング</strong>は、分断されたノードを<strong>強制的に隔離する</strong>手法です

フェンシングの目的は、分断されたノードが共有リソースにアクセスすることを物理的に阻止することです

最も積極的なフェンシング手法に <strong>STONITH（Shoot The Other Node In The Head）</strong>があります

STONITH は、分断されたノードを電源レベルで強制的に停止させる手法です

たとえば、管理ポートを通じてノードの電源を切断します

ノードを停止させることで、そのノード上の Pod も確実に停止し、二重実行を防ぎます

### Kubernetes での対応

Kubernetes 自体は、完全なフェンシングの仕組みを内蔵していません

しかし、以下の仕組みを組み合わせて、スプリットブレインの影響を緩和しています

| 仕組み             | 役割                                                                         |
| ------------------ | ---------------------------------------------------------------------------- |
| etcd のクォーラム  | データの一貫性を保護し、分断された少数派が書き込みを行うことを防ぐ           |
| Lease オブジェクト | ノードの利用権に有効期限を設け、更新できないノードの権限を自動的に失効させる |
| Taint と Pod 退避  | NotReady なノードに Taint を付与し、Pod を別のノードに退避させる             |

### アプリケーション側の設計

Kubernetes が提供する仕組みだけでは、スプリットブレインを完全に防ぐことはできません

特にステートフルなアプリケーションでは、アプリケーション側の設計も重要になります

<strong>冪等性（べきとうせい）</strong>は、重要な設計原則の 1 つです

冪等性とは、同じ操作を何度実行しても結果が変わらない性質を指します

たとえば、「口座の残高を 1000 円に設定する」は冪等な操作です

何度実行しても結果は同じ 1000 円です

一方、「口座の残高に 1000 円を加算する」は冪等ではありません

2 回実行すると 2000 円加算されてしまいます

二重実行が発生する可能性がある環境では、操作を冪等に設計することで、同じ操作が複数回実行されてもデータの整合性が保たれます

スプリットブレインは分散システムにおいて完全な解決が困難な問題であり、etcd のクォーラム、Lease、Taint による緩和と、アプリケーション側の冪等な設計を組み合わせて対処することが求められます

---

## 用語集

| 用語                                        | 説明                                                                                                                      |
| ------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- |
| スプリットブレイン（Split-Brain）           | ネットワーク分断により、クラスタが複数のグループに分かれ、各グループが独立に動作してしまう問題                            |
| ネットワーク分断（Network Partition）       | ネットワーク障害により、クラスタ内のノード間の通信が途絶える状態                                                          |
| クォーラム（Quorum）                        | 操作を確定するために必要な最小限のノード数であり、過半数で定義される。etcd はクォーラムの合意なしに書き込みを受け付けない |
| Lease（リース）                             | リソースの利用権に有効期限を設ける仕組み。期限内に更新しなければ権限が失効する                                            |
| フェンシング（Fencing）                     | 分断されたノードを強制的に隔離し、共有リソースへのアクセスを阻止する手法                                                  |
| STONITH（Shoot The Other Node In The Head） | 分断されたノードを電源レベルで強制的に停止させるフェンシング手法                                                          |
| 二重実行（Dual Execution）                  | 同じアプリケーションの同じ Pod が複数のノードで同時に動作する状態                                                         |
| ステートレス（Stateless）                   | リクエストごとに独立して処理を行い、サーバー側に状態を持たないアプリケーションの性質                                      |
| ステートフル（Stateful）                    | 処理の間で状態を保持し、共有リソース（ストレージなど）に依存するアプリケーションの性質                                    |
| 冪等性（Idempotency）                       | 同じ操作を何度実行しても結果が変わらない性質。二重実行が発生しうる環境での重要な設計原則                                  |
| NotReady                                    | ノードがハートビートを送信しなくなった場合にマークされる状態。Node コントローラがこの状態への変更を行う                   |
| Taint（テイント）                           | ノードに「問題がある」ことをマークする仕組み。対応する Toleration を持たない Pod はスケジュールされない                   |

---

## 参考資料

このページの内容は、以下のソースに基づいています

<strong>Kubernetes ノード管理</strong>

- [Nodes](https://kubernetes.io/docs/concepts/architecture/nodes/)
  - Node コントローラ、ハートビート、Lease オブジェクトの仕組みの公式ドキュメント

- [Node Lease](https://kubernetes.io/docs/concepts/architecture/leases/)
  - Lease オブジェクトによるノードの可用性確認の公式ドキュメント

<strong>etcd と分散合意</strong>

- [etcd Documentation](https://etcd.io/docs/)
  - etcd のクォーラム、障害耐性、分散キーバリューストアの仕様と設計を扱う公式ドキュメント

- "In Search of an Understandable Consensus Algorithm" (Ongaro & Ousterhout, 2014)
  - https://raft.github.io/raft.pdf
  - Raft 合意アルゴリズムの原論文であり、クォーラムの仕組みとネットワーク分断時の安全性について詳述している

<strong>分散システムの理論</strong>

- "Perspectives on the CAP Theorem" (Gilbert & Lynch, 2012)
  - 分散システムにおける一貫性（Consistency）、可用性（Availability）、分断耐性（Partition Tolerance）のトレードオフに関する論文
